{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656ecdf2-1ed8-411e-80e6-9e7bf216aedc",
   "metadata": {},
   "source": [
    "## Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ee02d-64af-4955-b591-6d7f932ecc4f",
   "metadata": {},
   "source": [
    "We dealt with the following data:\n",
    "\n",
    "- `stop_times` (timetable data)\n",
    "- `calendar` (timetable data)\n",
    "- `routes` (timetable data)\n",
    "- `trips` (timetable data)\n",
    "- `stops` (timetable data)\n",
    "- `actual_condition` (real sbb data)\n",
    "\n",
    "\n",
    "They will be loaded down there. View data structure with `dataName.printSchema()`, to view few (e.g. 5) rows, use `dataName.show(5)`\n",
    "\n",
    "timetable data are on purpose only read from data recorded at 2022/06/01, recall that:\n",
    ">The timetables are updated weekly. It is ok to assume that the weekly changes are small, and a timetable for\n",
    "a given week is thus the same for the full year - use the schedule of the most recent week for the day of the trip.\n",
    "\n",
    "It is also way too expensive to load all data (in fact I tried, the session keeps crushing)\n",
    "\n",
    "---\n",
    "\n",
    "**Proprocessed data:**\n",
    "- `stops_in_15`: Filtered out all stops outside of 15km range; \n",
    "- `walk_map`: Calculated the walking time between walkable stops, date-independent\n",
    "- `weekday_trans`: Combining all timetable data and filtering out weekends, non-business hours; (within 15km range)\n",
    "- `trans_map`: Time that takes from one stop to another for a trip (date-dependent), similar to `walk_map`\n",
    "\n",
    "---\n",
    "\n",
    "**UI:**\n",
    "- Doesn't support fuzzy search, must use exact stop names;\n",
    "- Arrive time input format HH:MM, no spaces.\n",
    "\n",
    "---\n",
    "\n",
    "**Graph:**\n",
    "Directed graph, node is `stop_id`; edge takes two values:\n",
    "- `time`: in seconds, the time it takes from one node to another;\n",
    "- `trip_id`: the id of trip, if is walk, `trip_id` = 'walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a0e7e92-5438-4fff-9404-bf424641426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (3.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (12.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from pyarrow) (1.23.5)\n",
      "Requirement already satisfied: fastparquet in /opt/conda/lib/python3.9/site-packages (2023.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from fastparquet) (21.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from fastparquet) (2023.5.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from fastparquet) (1.5.3)\n",
      "Requirement already satisfied: cramjam>=2.3 in /opt/conda/lib/python3.9/site-packages (from fastparquet) (2.6.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.9/site-packages (from fastparquet) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2022.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->fastparquet) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "#Installing dependencies\n",
    "!pip install networkx\n",
    "!pip install pyarrow\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665567f-1764-48b1-82fc-d4aa56344353",
   "metadata": {},
   "source": [
    "## Spark stuff\n",
    "\n",
    "**In peak hours the sesson might not be able to start** and throw:\n",
    "```\n",
    "The code failed because of a fatal error:\n",
    "\tSession xxxx did not start up in 60 seconds..\n",
    "\n",
    "Some things to try:\n",
    "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
    "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
    "c) Restart the kernel.\n",
    "```\n",
    "Solution is to keep retrying ;) good luck for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53caff7c-0de2-4e15-8fb8-c2340bbe98df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'haolli-final-project', 'executorMemory': '4G', 'executorCores': 4, 'numExecutors': 10, 'conf': {'spark.jars.repositories': 'https://repos.spark-packages.org'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3291</td><td>application_1680948035106_3036</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3036/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster062.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3036_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "import os\n",
    "import json\n",
    "from IPython import get_ipython\n",
    "\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "\n",
    "configuration = dict(\n",
    "    name = f\"{username}-final-project\",\n",
    "    executorMemory = \"4G\",\n",
    "    executorCores = 4,\n",
    "    numExecutors = 10,\n",
    "    conf = {\n",
    "        \"spark.jars.repositories\": \"https://repos.spark-packages.org\",\n",
    "    }\n",
    ")\n",
    "\n",
    "get_ipython().run_cell_magic('configure', line=\"-f\", \n",
    "                             cell=json.dumps(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dd6dd8-6264-4849-bfab-89ede4b64a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3400</td><td>application_1680948035106_3151</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3151/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3151_01_000001/ebouille\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440d7004-dce0-42df-ac6f-ba31a2020e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301e5e7-06c7-403a-b5b4-ff05fc629d2f",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a9e47-7f2d-4e35-8e49-72198334ca9b",
   "metadata": {},
   "source": [
    "### data reading\n",
    "\n",
    "We use data one week before the final presentation but in the year of 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0606136-cdb8-4d34-951f-c995f888380a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orc_file_path = \"/data/sbb/part_orc/timetables\"\n",
    "stop_times = spark.read.orc(orc_file_path + \"/stop_times/year=2022/month=6/day=1\")\n",
    "calendar = spark.read.orc(orc_file_path + \"/calendar/year=2022/month=6/day=1\")\n",
    "routes = spark.read.orc(orc_file_path + \"/routes/year=2022/month=6/day=1\")\n",
    "trips = spark.read.orc(orc_file_path + \"/trips/year=2022/month=6/day=1\")\n",
    "csv_file_path = \"/data/sbb/part_csv/timetables\"\n",
    "stops_csv = spark.read.csv(csv_file_path + \"/stops/year=2022/month=06/day=01\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bddff2-3335-41ea-966b-34201948c012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date_of_trip: string (nullable = true)\n",
      " |-- Trip_id: string (nullable = true)\n",
      " |-- Operator_id: string (nullable = true)\n",
      " |-- Operator_abk: string (nullable = true)\n",
      " |-- Operator_name: string (nullable = true)\n",
      " |-- Transport_type: string (nullable = true)\n",
      " |-- Train_number(train): string (nullable = true)\n",
      " |-- Service type(train): string (nullable = true)\n",
      " |-- Circulation_id: string (nullable = true)\n",
      " |-- Means_of_transport_text: string (nullable = true)\n",
      " |-- If_additional: string (nullable = true)\n",
      " |-- If_failed: string (nullable = true)\n",
      " |-- Stop_id: string (nullable = true)\n",
      " |-- Stop_name: string (nullable = true)\n",
      " |-- Arrival_time: string (nullable = true)\n",
      " |-- Actual_arrival_time: string (nullable = true)\n",
      " |-- an_prognose_status: string (nullable = true)\n",
      " |-- Departure_time: string (nullable = true)\n",
      " |-- Actual_departure_time: string (nullable = true)\n",
      " |-- ab_prognose_status: string (nullable = true)\n",
      " |-- Not_stop: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "actual_temp = spark.read.load(\"/data/sbb/part_orc/istdaten\", format=\"orc\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
    "actual_condition = actual_temp.withColumnRenamed(\"betriebstag\", \"Date_of_trip\")\\\n",
    "                .withColumnRenamed(\"fahrt_bezeichner\", \"Trip_id\")\\\n",
    "                .withColumnRenamed(\"betreiber_id\", \"Operator_id\")\\\n",
    "                .withColumnRenamed(\"betreiber_abk\", \"Operator_abk\")\\\n",
    "                .withColumnRenamed(\"betreiber_name\", \"Operator_name\")\\\n",
    "                .withColumnRenamed(\"produkt_id\", \"Transport_type\")\\\n",
    "                .withColumnRenamed(\"linien_id\", \"Train_number(train)\")\\\n",
    "                .withColumnRenamed(\"linien_text\", \"Service type(train)\")\\\n",
    "                .withColumnRenamed(\"umlauf_id\", \"Circulation_id\")\\\n",
    "                .withColumnRenamed(\"verkehrsmittel_text\", \"Means_of_transport_text\")\\\n",
    "                .withColumnRenamed(\"zusatzfahrt_tf\", \"If_additional\")\\\n",
    "                .withColumnRenamed(\"faellt_aus_tf\", \"If_failed\")\\\n",
    "                .withColumnRenamed(\"bpuic\", \"Stop_id\")\\\n",
    "                .withColumnRenamed(\"haltestellen_name\", \"Stop_name\")\\\n",
    "                .withColumnRenamed(\"ankunftszeit\", \"Arrival_time\")\\\n",
    "                .withColumnRenamed(\"an_prognose\", \"Actual_arrival_time\")\\\n",
    "                .withColumnRenamed(\"abfahrtszeit\", \"Departure_time\")\\\n",
    "                .withColumnRenamed(\"ab_prognose\", \"Actual_departure_time\")\\\n",
    "                .withColumnRenamed(\"durchfahrt_tf\", \"Not_stop\")\n",
    "actual_condition.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f53aa-5aa3-4225-bc25-0486de28d812",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e62a7-089b-4153-8f49-d1e300148fac",
   "metadata": {},
   "source": [
    "We filter out all stations that are 15kms away from the given Zurich location.\n",
    "\n",
    "For distance calculation, refer to [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ba279d-7026-407e-bad4-eff22b312dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 40077 stops before\n",
      "There are 1888 stops that are in 15km radius of Zurich HB\n",
      "+-------------+--------------------+----------------+----------------+-------------+--------------+\n",
      "|      stop_id|           stop_name|        stop_lat|        stop_lon|location_type|parent_station|\n",
      "+-------------+--------------------+----------------+----------------+-------------+--------------+\n",
      "|      8500926|Oetwil a.d.L., Sc...|47.4236270123012| 8.4031825286317|         null|          null|\n",
      "|      8502186|Dietikon Stoffelbach|47.3933267759652|8.39896044679575|         null| Parent8502186|\n",
      "|8502186:0:1/2|Dietikon Stoffelbach|47.3933997509195|8.39894248049007|         null| Parent8502186|\n",
      "|      8502187|Rudolfstetten Hof...|47.3646702178563|8.37695172233176|         null| Parent8502187|\n",
      "|8502187:0:1/2|Rudolfstetten Hof...|47.3647371479356|8.37703257070734|         null| Parent8502187|\n",
      "+-------------+--------------------+----------------+----------------+-------------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "@F.udf(returnType=FloatType())\n",
    "\n",
    "#Implement the Haversine formula. \n",
    "def distance_calculation(latitude_1, longitude_1, latitude_2, longitude_2):\n",
    "    #Use Haversine formula. \n",
    "    #The Haversine formula calculates the distance between two points on a sphere \n",
    "    #(such as the Earth) based on their latitude and longitude.\n",
    "    radius_of_Earth = 6371.0 #Earth radius, just refer to the actual data \n",
    "    \n",
    "    #First, Convert latitude and longitude from degrees to radians\n",
    "    latitude_1 = radians(float(latitude_1))\n",
    "    latitude_2 = radians(float(latitude_2))\n",
    "    longitude_1 = radians(float(longitude_1))\n",
    "    longitude_2 = radians(float(longitude_2))\n",
    "\n",
    "    ## Haversine formula implementation\n",
    "    delta_latitude = latitude_2 - latitude_1\n",
    "    delta_longitude = longitude_2 - longitude_1\n",
    "\n",
    "    a = cos(latitude_1)*cos(latitude_2)*sin(delta_longitude/2)**2+sin(delta_latitude/2)**2\n",
    "    c = 2*atan2(sqrt(a), sqrt(1-a))\n",
    "\n",
    "    distance = radius_of_Earth * c \n",
    "    return distance\n",
    "\n",
    "print(\"We have \" + str(stops_csv.distinct().count()) + \" stops before\")\n",
    "\n",
    "stops_in_15 = stops_csv.where(distance_calculation(F.lit(47.378177), F.lit(8.540192), F.col(\"stop_lat\"), F.col(\"stop_lon\")) <=15)\n",
    "\n",
    "print(\"There are \" + str(stops_in_15.distinct().count()) + \" stops that are in 15km radius of Zurich HB\")\n",
    "\n",
    "stops_in_15.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cc168-a81b-466f-a32a-df10874cb970",
   "metadata": {},
   "source": [
    "With the within-15km stops, we want to preprocess the walking time, for this there are two steps:\n",
    "- Filter out stations that are too far away for walking (>500m)\n",
    "- Calculate walking time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7045bb6f-d6f4-422c-80fc-6014e19c2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walking_df = stops_in_15.select(F.col(\"stop_id\").alias(\"stop_id_1\"), F.col(\"stop_name\").alias(\"stop_name_1\"), F.col(\"stop_lat\").alias(\"stop_lat_1\"), F.col(\"stop_lon\").alias(\"stop_lon_1\")) \\\n",
    "    .crossJoin(stops_in_15.select(F.col(\"stop_id\").alias(\"stop_id_2\"), F.col(\"stop_name\").alias(\"stop_name_2\"), F.col(\"stop_lat\").alias(\"stop_lat_2\"),F.col(\"stop_lon\").alias(\"stop_lon_2\"))) \\\n",
    "    .withColumn(\"distance\", distance_calculation(F.col(\"stop_lat_1\"), F.col(\"stop_lon_1\"), F.col(\"stop_lat_2\"), F.col(\"stop_lon_2\"))) \\\n",
    "    .select(F.col(\"stop_id_1\"), F.col(\"stop_name_1\"), F.col(\"stop_id_2\"), F.col(\"stop_name_2\"), F.col(\"distance\")) \\\n",
    "    .filter(\"distance<=0.5 and distance>0.0\")\n",
    "\n",
    "walking_df = walking_df.withColumn(\"used_time\", walking_df.distance*1200).select(\"stop_id_1\",\"stop_name_1\",\"stop_id_2\",\"stop_name_2\",\"used_time\")\n",
    "walk_map = walking_df.withColumn('trip_id',F.lit('walk')).withColumn('stops_id1_dep',F.lit('null')).withColumn('stops_id2_arr',F.lit('null'))\\\n",
    "                        .withColumn('route_desc', F.lit('walk')).select('trip_id','stop_id_1','stop_id_2','used_time','stops_id1_dep','stops_id2_arr','route_desc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24047ff5-adb1-4503-946c-251ab99d5b04",
   "metadata": {},
   "source": [
    "According to the requirement of the task, we select only the weekdays.\n",
    "\n",
    "The weekdays filtering can be done in calendar and then we use service_id to join other dataframes to get the transportation methods in weekdays.\n",
    "\n",
    "We then implement all the joins using primary keys, and filte out not-business times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3607543-d928-4a5f-b50c-00a617e6a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weekdays_mask = calendar.where(\"monday = TRUE and tuesday = TRUE and wednesday = TRUE and thursday = TRUE and friday = TRUE\").select('service_id')\n",
    "weekday_trips = trips.join(weekdays_mask, \"service_id\")\n",
    "weekday_trips_routes = weekday_trips.join(routes, \"route_id\")\n",
    "weekday_stop_times = stop_times.join(weekday_trips_routes, \"trip_id\")\n",
    "weekday_trans = weekday_stop_times.join(stops_in_15, \"stop_id\")\n",
    "time_range = (8,18)\n",
    "weekday_trans = weekday_trans.filter(F.hour(weekday_trans.arrival_time)>=time_range[0])\\\n",
    "                        .filter(F.hour(weekday_trans.departure_time)>=time_range[0])\\\n",
    "                        .filter(F.hour(weekday_trans.arrival_time)<=time_range[1])\\\n",
    "                        .filter(F.hour(weekday_trans.departure_time)<=time_range[1])\\\n",
    "                        .select(\"trip_id\",\"stop_id\",\"stop_name\",\"arrival_time\",\"departure_time\",\"stop_sequence\", \"route_desc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507c550-40d0-4ac4-ad92-796139ac01bc",
   "metadata": {},
   "source": [
    "## Graph building\n",
    "\n",
    "Building the edges (time spend between two stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eaf170-7fa0-49ab-8abd-dee9f2241ed4",
   "metadata": {},
   "source": [
    "For one trip (identified by `trip_id`), we aggregate info about it and store it all in one row (per `trip_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24999e60-fa27-4e2c-865a-f956d8e89af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import ArrayType, StringType, StructType, StructField, BooleanType\n",
    "\n",
    "@F.udf(returnType=ArrayType(StringType()))\n",
    "def to_line(column):\n",
    "    set_names = column.split(';')\n",
    "    line_set = []\n",
    "    for i in range(len(set_names) - 1):\n",
    "        line_set.append([set_names[i], set_names[i+1]])\n",
    "    return line_set\n",
    "\n",
    "@F.udf(returnType=ArrayType(StringType()))\n",
    "def to_timetable(arr, dep):\n",
    "    arr_time = arr.split(';')\n",
    "    dep_time = dep.split(';')\n",
    "    line_set = []\n",
    "    for i in range(len(arr_time) - 1):\n",
    "        line_set.append([dep_time[i], arr_time[i+1]])\n",
    "    return line_set\n",
    "\n",
    "@F.udf(returnType=ArrayType(StringType()))\n",
    "def to_transtype(route_desc):\n",
    "    routes_desc = route_desc.split(';')\n",
    "    routes = []\n",
    "    for i in range(len(routes_desc)):\n",
    "        routes.append(routes_desc[i])\n",
    "    return routes\n",
    "\n",
    "@F.udf(returnType=ArrayType(FloatType()))\n",
    "def calculate_time(arr, dep):\n",
    "    arr_time = arr.split(';')\n",
    "    dep_time = dep.split(';')\n",
    "    time_set = []\n",
    "    for i in range(len(arr_time) - 1):\n",
    "        time = (datetime.strptime(arr_time[i+1], '%H:%M:%S') - datetime.strptime(dep_time[i], '%H:%M:%S')).total_seconds()\n",
    "        time_set.append(time)\n",
    "    return time_set\n",
    "\n",
    "@F.udf(returnType=StringType())\n",
    "def remove_parentheses(cols):\n",
    "    return cols[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cc8b6d6-e46b-434d-8801-6ad3dc8f21e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import types as T\n",
    "\n",
    "schema = T.StructType([\n",
    "    T.StructField(\"stops_id_group\", T.StringType()),\n",
    "    T.StructField(\"stops_name_group\", T.StringType()),\n",
    "    T.StructField(\"used_time\", T.StringType()),\n",
    "    T.StructField(\"stops_time_group\", T.StringType()),\n",
    "    T.StructField(\"trans_type\", T.StringType())\n",
    "])\n",
    "\n",
    "def zip_arrays(stops_id_group, stops_name_group, used_time, stops_time_group, trans_type):\n",
    "    return list(zip(stops_id_group, stops_name_group, used_time, stops_time_group, trans_type))\n",
    "\n",
    "combine = F.udf(zip_arrays, returnType=T.ArrayType(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e7ec47b-63e5-47b7-8010-f7337838ddf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced_rdd = weekday_trans.rdd.map(\n",
    "    lambda row: (\n",
    "        row[0],\n",
    "        [(row[1], row[2], row[3], row[4], row[5], row[6])]\n",
    "    )\n",
    ").reduceByKey(\n",
    "    lambda x, y: x + y\n",
    ").map(\n",
    "    lambda row: (\n",
    "        row[0],\n",
    "        sorted(row[1], key=lambda text: int(text[4]))\n",
    "    )\n",
    ").map(\n",
    "    lambda row: (\n",
    "        row[0],\n",
    "        \";\".join([e[0] for e in row[1]]),\n",
    "        \";\".join([e[1] for e in row[1]]),\n",
    "        \";\".join([e[2] for e in row[1]]),\n",
    "        \";\".join([e[3] for e in row[1]]),\n",
    "        \";\".join([e[4] for e in row[1]]),\n",
    "        \";\".join([e[5] for e in row[1]])\n",
    "    )\n",
    ")\n",
    "\n",
    "reduced_df = reduced_rdd.toDF(\n",
    "    [\"trip_id\", \"stop_id\", \"stop_name\", \"arrival_time\", \"departure_time\", \"stop_sequence\", \"route_desc\"]\n",
    ")\n",
    "\n",
    "merge2stops_df = reduced_df.withColumn(\n",
    "    'stops_id_group', to_line(reduced_df.stop_id)\n",
    ").withColumn(\n",
    "    'stops_name_group', to_line(reduced_df.stop_name)\n",
    ").withColumn(\n",
    "    'stops_time_group', to_timetable(reduced_df.arrival_time, reduced_df.departure_time)\n",
    ").withColumn(\n",
    "    'used_time', calculate_time(reduced_df.arrival_time, reduced_df.departure_time)\n",
    ").withColumn(\n",
    "    'trans_type', to_transtype(reduced_df.route_desc)\n",
    ").select(\n",
    "    'trip_id', 'stops_id_group', 'stops_name_group', 'used_time', 'stops_time_group', 'trans_type'\n",
    ")\n",
    "\n",
    "merge2stops_df = merge2stops_df.withColumn(\n",
    "    \"agg_info\",\n",
    "    combine(merge2stops_df.stops_id_group, merge2stops_df.stops_name_group, merge2stops_df.used_time,\n",
    "            merge2stops_df.stops_time_group, merge2stops_df.trans_type)\n",
    ").withColumn(\n",
    "    \"agg_info\", F.explode(\"agg_info\")\n",
    ").select(\n",
    "    \"trip_id\", F.col(\"agg_info.stops_id_group\").alias(\"stops_id_group\"),\n",
    "    F.col(\"agg_info.stops_name_group\").alias(\"stops_name_group\"),\n",
    "    F.col(\"agg_info.used_time\").alias(\"used_time\"),\n",
    "    F.col(\"agg_info.stops_time_group\").alias(\"stops_time_group\"),\n",
    "    F.col(\"agg_info.trans_type\").alias(\"route_desc\")\n",
    ")\n",
    "\n",
    "merge2stops_df = merge2stops_df.withColumn(\n",
    "    'new_id_group', remove_parentheses(merge2stops_df.stops_id_group)\n",
    ").withColumn(\n",
    "    'new_name_group', remove_parentheses(merge2stops_df.stops_name_group)\n",
    ").withColumn(\n",
    "    'new_time_group', remove_parentheses(merge2stops_df.stops_time_group)\n",
    ")\n",
    "\n",
    "trans_map = merge2stops_df.select(\n",
    "    \"trip_id\",\n",
    "    F.split(\"new_id_group\", \",\")[0].alias(\"stop_id1\"),\n",
    "    F.split(\"new_id_group\", \", \")[1].alias(\"stop_id2\"),\n",
    "    \"used_time\",\n",
    "    F.split(\"new_time_group\", \",\")[0].alias(\"stop_id1_dep\"),\n",
    "    F.split(\"new_time_group\", \", \")[1].alias(\"stop_id2_arr\"),\n",
    "    \"route_desc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a44d25b-7953-4e4e-8d07-e2a44fa99c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+---------+------------+------------+----------+\n",
      "|             trip_id|stop_id1|stop_id2|used_time|stop_id1_dep|stop_id2_arr|route_desc|\n",
      "+--------------------+--------+--------+---------+------------+------------+----------+\n",
      "|1104.TA.91-3-j22-...| 8591233| 8591199|     60.0|    15:11:00|    15:12:00|         T|\n",
      "|1104.TA.91-3-j22-...| 8591199| 8503083|     60.0|    15:12:00|    15:13:00|         T|\n",
      "|1104.TA.91-3-j22-...| 8503083| 8591202|    120.0|    15:13:00|    15:15:00|         T|\n",
      "|1104.TA.91-3-j22-...| 8591202| 8591239|     60.0|    15:15:00|    15:16:00|         T|\n",
      "|1104.TA.91-3-j22-...| 8591239| 8591287|    120.0|    15:16:00|    15:18:00|         T|\n",
      "+--------------------+--------+--------+---------+------------+------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "trans_map.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16ab4fa6-6ec7-498d-9cd6-7cb511c7348b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------+---------+-------------+-------------+----------+\n",
      "|trip_id|stop_id_1|    stop_id_2|used_time|stops_id1_dep|stops_id2_arr|route_desc|\n",
      "+-------+---------+-------------+---------+-------------+-------------+----------+\n",
      "|   walk|  8500926|      8590616|146.91576|         null|         null|      walk|\n",
      "|   walk|  8500926|      8590737|359.59048|         null|         null|      walk|\n",
      "|   walk|  8502186|8502186:0:1/2| 9.871648|         null|         null|      walk|\n",
      "|   walk|  8502186|      8502270| 552.5724|         null|         null|      walk|\n",
      "|   walk|  8502186|      8590200| 580.6377|         null|         null|      walk|\n",
      "+-------+---------+-------------+---------+-------------+-------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# the walking time we processed earlier\n",
    "walk_map.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967f862-6cbf-49d1-8e00-bafcf54fa2bd",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "187e3047-0f76-4aa7-882f-b39991278562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".widget-label {\n",
       "    min-width: 150px;\n",
       "    text-align: right;\n",
       "    padding-right: 10px;\n",
       "}\n",
       "#container {\n",
       "    background-color: orange;\n",
       "    color: white;\n",
       "}\n",
       "#title {\n",
       "    color: red;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2 id=\"title\">Route Planner</h2>'), Text(value='Küsnacht ZH', description='Departu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets, interact, VBox\n",
    "from IPython.display import display, HTML\n",
    "import datetime\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_hour = current_datetime.hour\n",
    "current_minute = str(current_datetime.minute)\n",
    "proposed_hour = str(current_hour + 4)\n",
    "\n",
    "def create_schedule(change):\n",
    "    Departure = departure_widget.value\n",
    "    Destination = destination_widget.value\n",
    "    timeInput = input_widget.value\n",
    "    hour, minute = map(int, timeInput.split(\":\"))\n",
    "    time = hour + minute / 60\n",
    "    \n",
    "    schedule_info = {\n",
    "        'dep': [Departure],\n",
    "        'destination': [Destination],\n",
    "        'arrival_time': [time]\n",
    "    }\n",
    "    \n",
    "    schedule_df = pd.DataFrame(schedule_info)\n",
    "    \n",
    "    schedule_df.to_csv('./info.csv')\n",
    "\n",
    "    \n",
    "css = \"\"\"\n",
    ".widget-label {\n",
    "    min-width: 150px;\n",
    "    text-align: right;\n",
    "    padding-right: 10px;\n",
    "}\n",
    "#container {\n",
    "    background-color: orange;\n",
    "    color: white;\n",
    "}\n",
    "#title {\n",
    "    color: red;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "html = \"<style>{}</style>\".format(css)\n",
    "display(HTML(html))\n",
    "    \n",
    "title = widgets.HTML('<h2 id=\"title\">Route Planner</h2>')\n",
    "departure_widget = widgets.Text(value='Küsnacht ZH', description='Departure')\n",
    "destination_widget = widgets.Text(value='Zürich, Neeserweg', description='Destination')\n",
    "input_widget = widgets.Text(value = proposed_hour + \":\"+current_minute, description = 'Arrive at (HH:MM)')\n",
    "\n",
    "input_widget.continuous_update = False\n",
    "input_widget.observe(create_schedule, 'value')\n",
    "\n",
    "container = VBox([title, departure_widget, destination_widget,input_widget], layout=widgets.Layout(id='container'))\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffbe18-3efd-4e79-a907-c5859947b997",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Reading input data and sending it to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d69248de-7b5d-4fae-a277-ece57df7d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import pandas as pd\n",
    "schedule_df = pd.read_csv('./info.csv')\n",
    "time_local = schedule_df.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48500e26-cf3c-4cdc-a04a-25eabd23d1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'schedule_df' as 'schedule_df' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i schedule_df -t df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874f2ba-12fa-4f54-aff3-b3a2566a1740",
   "metadata": {},
   "source": [
    "Getting the stop id corresponding to the stop name. \n",
    "\n",
    "Here I preserve only the root stations (no parent stations) and distinct them based on coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d68551c-692c-4a5c-a7ed-88ae5d6c0b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_name1 = schedule_df.select('dep').rdd.flatMap(lambda x: x).collect()[0]\n",
    "stop_name2 = schedule_df.select('destination').rdd.flatMap(lambda x: x).collect()[0]\n",
    "time = schedule_df.select('arrival_time').rdd.flatMap(lambda x: x).collect()[0]\n",
    "\n",
    "stop1 = stops_in_15.filter(stops_in_15[\"stop_name\"]==stop_name1)\\\n",
    ".filter(stops_in_15['parent_station'].isNull())\\\n",
    ".dropDuplicates(['stop_lat', 'stop_lon'])\\\n",
    "\n",
    "stop2 = stops_in_15.filter(stops_in_15[\"stop_name\"]==stop_name2)\\\n",
    ".filter(stops_in_15['parent_station'].isNull())\\\n",
    ".dropDuplicates(['stop_lat', 'stop_lon'])\\\n",
    "\n",
    "# the calculation is not stable as I observe, sometimes there are multiple results with\n",
    "# exactly the same coordinates and the only difference is the id, sometimes this does\n",
    "# not happen. Therefore I take the first element of the result.\n",
    "\n",
    "# stop_id1, stop_id2 is a string\n",
    "stop_id1 = stop1.select('stop_id').first().stop_id\n",
    "stop_id2 = stop2.select('stop_id').first().stop_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4d98e-2a60-4caa-8eb5-a921f6f6ef02",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19a67c-e86d-4870-9bbf-40bb53398f79",
   "metadata": {},
   "source": [
    "Before building the graph, we filter out trips that are:\n",
    "- Arriving later than our desired arrivial time;\n",
    "- Arriving too early (more than 2 hours before) than our desired arrivial time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "848a1431-a636-4930-984a-87e9f7b3913c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arrival_time_in_hours = F.hour(\"arrival_time\") + F.minute(\"arrival_time\") / 60\n",
    "\n",
    "start_time = time - 2\n",
    "end_time = time\n",
    "\n",
    "trips_arriving_in_time_range = weekday_trans.filter(arrival_time_in_hours.between(start_time, end_time))\n",
    "\n",
    "distinct_trip_ids = trips_arriving_in_time_range.select(\"trip_id\")\n",
    "\n",
    "trans_map = trans_map.join(distinct_trip_ids,'trip_id')\n",
    "\n",
    "trans_map = trans_map.union(walk_map)\n",
    "\n",
    "trans_map.write.parquet('/user/{0}/file/'.format(username), mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "895174a9-89b4-466f-aa5b-860739e1ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "from hdfs3 import HDFileSystem\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "hdfs = HDFileSystem(host='hdfs://iccluster044.iccluster.epfl.ch', port=8020, user='ebouille')\n",
    "files = hdfs.glob('/user/{0}/file/*.parquet'.format(username))\n",
    "trans = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        trans = pd.concat([trans, pd.read_parquet(f)])\n",
    "\n",
    "edges = trans.values.tolist()\n",
    "\n",
    "for i, row in enumerate(edges):\n",
    "    edges[i] = (row[1], row[2], {\"time\": float(row[3]), \"trip_id\": row[0]})\n",
    "\n",
    "g = nx.DiGraph()\n",
    "g.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef2449e-6588-43ba-bac4-d37cc679d5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 168.71622, 'trip_id': 'walk'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "edge_data = g.get_edge_data('8591365', '8591329')\n",
    "edge_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

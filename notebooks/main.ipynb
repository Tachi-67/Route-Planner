{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b665567f-1764-48b1-82fc-d4aa56344353",
   "metadata": {},
   "source": [
    "## Spark stuff\n",
    "\n",
    "**In peak hours the sesson might not be able to start** and throw:\n",
    "```\n",
    "The code failed because of a fatal error:\n",
    "\tSession xxxx did not start up in 60 seconds..\n",
    "\n",
    "Some things to try:\n",
    "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
    "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
    "c) Restart the kernel.\n",
    "```\n",
    "Solution is to keep retrying ;) good luck for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53caff7c-0de2-4e15-8fb8-c2340bbe98df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'haolli-final-project', 'executorMemory': '4G', 'executorCores': 4, 'numExecutors': 10, 'conf': {'spark.jars.repositories': 'https://repos.spark-packages.org', 'spark.jars.packages': 'graphframes:graphframes:0.8.2-spark2.4-s_2.11'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3127</td><td>application_1680948035106_2893</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_2893/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_2893_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3270</td><td>application_1680948035106_3027</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3027/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster061.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3027_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3291</td><td>application_1680948035106_3036</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3036/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster062.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3036_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3300</td><td>application_1680948035106_3045</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3045/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster055.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3045_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3301</td><td>application_1680948035106_3046</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3046/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster062.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3046_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3303</td><td>application_1680948035106_3047</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3047/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster056.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3047_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3304</td><td>application_1680948035106_3049</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3049/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster062.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3049_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3311</td><td>application_1680948035106_3056</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3056/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster061.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3056_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3320</td><td>application_1680948035106_3064</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3064/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster061.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3064_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>3322</td><td>application_1680948035106_3066</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3066/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster062.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3066_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "import os\n",
    "import json\n",
    "from IPython import get_ipython\n",
    "\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "\n",
    "configuration = dict(\n",
    "    name = f\"{username}-final-project\",\n",
    "    executorMemory = \"4G\",\n",
    "    executorCores = 4,\n",
    "    numExecutors = 10,\n",
    "    conf = {\n",
    "        \n",
    "        \"spark.jars.repositories\": \"https://repos.spark-packages.org\",\n",
    "        \"spark.jars.packages\": \"graphframes:graphframes:0.8.2-spark2.4-s_2.11\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "get_ipython().run_cell_magic('configure', line=\"-f\", \n",
    "                             cell=json.dumps(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dd6dd8-6264-4849-bfab-89ede4b64a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3323</td><td>application_1680948035106_3067</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1680948035106_3067/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster045.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1680948035106_3067_01_000001/ebouille\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440d7004-dce0-42df-ac6f-ba31a2020e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301e5e7-06c7-403a-b5b4-ff05fc629d2f",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a9e47-7f2d-4e35-8e49-72198334ca9b",
   "metadata": {},
   "source": [
    "### data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0606136-cdb8-4d34-951f-c995f888380a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orc_file_path = \"/data/sbb/part_orc/timetables\"\n",
    "stop_times = spark.read.orc(orc_file_path + \"/stop_times\")\n",
    "calendar = spark.read.orc(orc_file_path + \"/calendar\")\n",
    "routes = spark.read.orc(orc_file_path + \"/routes\")\n",
    "trips = spark.read.orc(orc_file_path + \"/trips\")\n",
    "csv_file_path = \"/data/sbb/part_csv/timetables\"\n",
    "stops_csv = spark.read.csv(csv_file_path + \"/stops\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830d0ce-e487-4d35-8cf5-80c62ecd0fb8",
   "metadata": {},
   "source": [
    "### looking at data & pre-pre processing (haolong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc19bc6-8671-4a2f-ac53-85d10473e692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+----------------+-------------+--------------+----+-----+---+\n",
      "|stop_id|           stop_name|        stop_lat|        stop_lon|location_type|parent_station|year|month|day|\n",
      "+-------+--------------------+----------------+----------------+-------------+--------------+----+-----+---+\n",
      "|1100008|Zell (Wiesental),...|47.7100842702352|7.85964788274668|         null|          null|2022|   12|  7|\n",
      "|1100009|Zell (Wiesental),...|47.7131911044794|7.86290876722849|         null|          null|2022|   12|  7|\n",
      "|1100010|           Atzenbach|47.7146175266411| 7.8723500608659|         null|          null|2022|   12|  7|\n",
      "|1100011|     Mambach, Brücke|47.7282088873189| 7.8774704579861|         null|          null|2022|   12|  7|\n",
      "|1100012|  Mambach, Mühlschau|47.7340818684375| 7.8813871126254|         null|          null|2022|   12|  7|\n",
      "+-------+--------------------+----------------+----------------+-------------+--------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "There are 9980770 records when reading data"
     ]
    }
   ],
   "source": [
    "stops_csv.show(5)\n",
    "stops_number = stops_csv.count()\n",
    "print(\"There are \" + str(stops_number) + \" records when reading data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49caff11-0cd0-49ed-8317-b24301f28a53",
   "metadata": {},
   "source": [
    "For one stop, there exist diffenent dates, they are useless, however pumps up our compuatation load.\n",
    "I'll just remove the time attributes and only leave one stop for each `stop_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e466ba7-bd65-47fd-a6c6-9ea4b1ea8ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 52277 records after removing records that only has different times"
     ]
    }
   ],
   "source": [
    "# dropping the time attributes\n",
    "# leaving only one entry for each `stop_id`\n",
    "stops_csv = stops_csv.drop('year', 'month', 'day')\n",
    "stops_csv = stops_csv.dropDuplicates(['stop_id'])\n",
    "print(\"There are \" + str(stops_csv.count()) + \" records after removing records that only has different times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f15fa2-6b55-4316-a33a-77e2959a6875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------+-----------+-------------+-----------+-------------+----+-----+---+\n",
      "|             trip_id|arrival_time|departure_time|    stop_id|stop_sequence|pickup_type|drop_off_type|year|month|day|\n",
      "+--------------------+------------+--------------+-----------+-------------+-----------+-------------+----+-----+---+\n",
      "|231.TA.91-9-F-j22...|    06:58:00|      06:58:00|8506206:0:4|            7|          0|            0|2022|   12|  7|\n",
      "|7041.TA.91-10-A-j...|    19:26:00|      19:26:00|    8500994|           20|          0|            0|2022|   12|  7|\n",
      "|232.TA.91-9-F-j22...|    08:35:00|      08:35:00|8506200:0:5|            1|          0|            0|2022|   12|  7|\n",
      "|7041.TA.91-10-A-j...|    19:27:00|      19:27:00|    8500079|           21|          0|            0|2022|   12|  7|\n",
      "|232.TA.91-9-F-j22...|    08:37:00|      08:37:00|8506201:0:1|            2|          0|            0|2022|   12|  7|\n",
      "+--------------------+------------+--------------+-----------+-------------+-----------+-------------+----+-----+---+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "stop_times.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f08535b-33ac-40b9-8983-93f7dd5d4cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+--------------------+---------------+------------+----+-----+---+\n",
      "|     route_id|service_id|             trip_id|       trip_headsign|trip_short_name|direction_id|year|month|day|\n",
      "+-------------+----------+--------------------+--------------------+---------------+------------+----+-----+---+\n",
      "|91-10-A-j22-1|  TA+8i000|1.TA.91-10-A-j22-...|Oberwil BL, Hüsli...|          51125|           0|2022|   12|  7|\n",
      "|91-10-A-j22-1|     TA+6V|10.TA.91-10-A-j22...|Oberwil BL, Hüsli...|          20605|           0|2022|   12|  7|\n",
      "|91-10-A-j22-1|  TA+f6n00|100.TA.91-10-A-j2...|Oberwil BL, Hüsli...|          22991|           0|2022|   12|  7|\n",
      "|91-10-A-j22-1|     TA+rV|1000.TA.91-10-A-j...|    Dornach, Bahnhof|          51153|           0|2022|   12|  7|\n",
      "|91-10-A-j22-1|     TA+rV|1001.TA.91-10-A-j...|    Dornach, Bahnhof|          51061|           0|2022|   12|  7|\n",
      "+-------------+----------+--------------------+--------------------+---------------+------------+----+-----+---+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "trips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0292e635-8ab4-443b-a52a-5d1c7dba2d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+---------+--------+------+--------+------+----------+--------+----+-----+---+\n",
      "|service_id|monday|tuesday|wednesday|thursday|friday|saturday|sunday|start_date|end_date|year|month|day|\n",
      "+----------+------+-------+---------+--------+------+--------+------+----------+--------+----+-----+---+\n",
      "|        TA|  TRUE|   TRUE|     TRUE|   FALSE| FALSE|   FALSE|  TRUE|  20221211|20221214|2022|   12|  7|\n",
      "|      TA#1|  TRUE|   TRUE|     TRUE|    TRUE|  TRUE|    TRUE|  TRUE|  20211212|20221210|2022|   12|  7|\n",
      "|  TA+00000| FALSE|  FALSE|    FALSE|   FALSE| FALSE|    TRUE| FALSE|  20211212|20221210|2022|   12|  7|\n",
      "|  TA+00010|  TRUE|   TRUE|     TRUE|   FALSE| FALSE|   FALSE|  TRUE|  20211212|20221210|2022|   12|  7|\n",
      "|  TA+001c0|  TRUE|   TRUE|     TRUE|    TRUE|  TRUE|   FALSE| FALSE|  20211212|20221210|2022|   12|  7|\n",
      "+----------+------+-------+---------+--------+------+--------+------+----------+--------+----+-----+---+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "calendar.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5da5f66-d2d7-4454-b221-18489861e948",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+----------------+---------------+----------+----------+----+-----+---+\n",
      "|      route_id|agency_id|route_short_name|route_long_name|route_desc|route_type|year|month|day|\n",
      "+--------------+---------+----------------+---------------+----------+----------+----+-----+---+\n",
      "|92-A00-5-j23-1|   80_BOD|               1|               |         B|       700|2022|   12|  7|\n",
      "|92-A00-5-j22-1|   80_BOD|               1|               |         B|       700|2022|   12|  7|\n",
      "|92-A00-4-j23-1|   80_BOD|               4|               |         B|       700|2022|   12|  7|\n",
      "|92-A00-4-j22-1|      839|               1|               |       EXB|       702|2022|   12|  7|\n",
      "|92-A00-3-j23-1|   80_BOD|               2|               |         B|       700|2022|   12|  7|\n",
      "+--------------+---------+----------------+---------------+----------+----------+----+-----+---+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "routes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24bddff2-3335-41ea-966b-34201948c012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date_of_trip: string (nullable = true)\n",
      " |-- Trip_id: string (nullable = true)\n",
      " |-- Operator_id: string (nullable = true)\n",
      " |-- Operator_abk: string (nullable = true)\n",
      " |-- Operator_name: string (nullable = true)\n",
      " |-- Transport_type: string (nullable = true)\n",
      " |-- Train_number(train): string (nullable = true)\n",
      " |-- Service type(train): string (nullable = true)\n",
      " |-- Circulation_id: string (nullable = true)\n",
      " |-- Means_of_transport_text: string (nullable = true)\n",
      " |-- If_additional: string (nullable = true)\n",
      " |-- If_failed: string (nullable = true)\n",
      " |-- Stop_id: string (nullable = true)\n",
      " |-- Stop_name: string (nullable = true)\n",
      " |-- Arrival_time: string (nullable = true)\n",
      " |-- Actual_arrival_time: string (nullable = true)\n",
      " |-- an_prognose_status: string (nullable = true)\n",
      " |-- Departure_time: string (nullable = true)\n",
      " |-- Actual_departure_time: string (nullable = true)\n",
      " |-- ab_prognose_status: string (nullable = true)\n",
      " |-- Not_stop: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+------------+--------------+-----------+------------+--------------------+--------------+-------------------+-------------------+--------------+-----------------------+-------------+---------+-------+--------------------+----------------+-------------------+------------------+----------------+---------------------+------------------+--------+----+-----+\n",
      "|Date_of_trip|       Trip_id|Operator_id|Operator_abk|       Operator_name|Transport_type|Train_number(train)|Service type(train)|Circulation_id|Means_of_transport_text|If_additional|If_failed|Stop_id|           Stop_name|    Arrival_time|Actual_arrival_time|an_prognose_status|  Departure_time|Actual_departure_time|ab_prognose_status|Not_stop|year|month|\n",
      "+------------+--------------+-----------+------------+--------------------+--------------+-------------------+-------------------+--------------+-----------------------+-------------+---------+-------+--------------------+----------------+-------------------+------------------+----------------+---------------------+------------------+--------+----+-----+\n",
      "|  13.02.2019|85:886:50902-0|     85:886|        RVBW|Regionale Verkehr...|           Bus|           85:886:4|                  4|              |                    NFB|        false|    false|8572581|Baden, Kantonsschule|13.02.2019 18:55|13.02.2019 18:56:22|              REAL|13.02.2019 18:55|  13.02.2019 18:56:32|              REAL|   false|2019|    2|\n",
      "+------------+--------------+-----------+------------+--------------------+--------------+-------------------+-------------------+--------------+-----------------------+-------------+---------+-------+--------------------+----------------+-------------------+------------------+----------------+---------------------+------------------+--------+----+-----+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "actual_temp = spark.read.load(\"/data/sbb/part_orc/istdaten\", format=\"orc\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
    "#Rename the columns, from German to English\n",
    "actual_condition = actual_temp.withColumnRenamed(\"betriebstag\", \"Date_of_trip\")\\\n",
    "                .withColumnRenamed(\"fahrt_bezeichner\", \"Trip_id\")\\\n",
    "                .withColumnRenamed(\"betreiber_id\", \"Operator_id\")\\\n",
    "                .withColumnRenamed(\"betreiber_abk\", \"Operator_abk\")\\\n",
    "                .withColumnRenamed(\"betreiber_name\", \"Operator_name\")\\\n",
    "                .withColumnRenamed(\"produkt_id\", \"Transport_type\")\\\n",
    "                .withColumnRenamed(\"linien_id\", \"Train_number(train)\")\\\n",
    "                .withColumnRenamed(\"linien_text\", \"Service type(train)\")\\\n",
    "                .withColumnRenamed(\"umlauf_id\", \"Circulation_id\")\\\n",
    "                .withColumnRenamed(\"verkehrsmittel_text\", \"Means_of_transport_text\")\\\n",
    "                .withColumnRenamed(\"zusatzfahrt_tf\", \"If_additional\")\\\n",
    "                .withColumnRenamed(\"faellt_aus_tf\", \"If_failed\")\\\n",
    "                .withColumnRenamed(\"bpuic\", \"Stop_id\")\\\n",
    "                .withColumnRenamed(\"haltestellen_name\", \"Stop_name\")\\\n",
    "                .withColumnRenamed(\"ankunftszeit\", \"Arrival_time\")\\\n",
    "                .withColumnRenamed(\"an_prognose\", \"Actual_arrival_time\")\\\n",
    "                .withColumnRenamed(\"abfahrtszeit\", \"Departure_time\")\\\n",
    "                .withColumnRenamed(\"ab_prognose\", \"Actual_departure_time\")\\\n",
    "                .withColumnRenamed(\"durchfahrt_tf\", \"Not_stop\")\n",
    "actual_condition.printSchema()\n",
    "actual_condition.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f53aa-5aa3-4225-bc25-0486de28d812",
   "metadata": {},
   "source": [
    "## Data proprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e62a7-089b-4153-8f49-d1e300148fac",
   "metadata": {},
   "source": [
    "We filter out all stations that are 15kms away from the given Zurich location.\n",
    "\n",
    "For distance calculation, refer to [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ba279d-7026-407e-bad4-eff22b312dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 52277 stops before\n",
      "There are 2264 stops that are in 15km radius of Zurich HB\n",
      "+--------+--------------------+----------------+----------------+-------------+--------------+\n",
      "| stop_id|           stop_name|        stop_lat|        stop_lon|location_type|parent_station|\n",
      "+--------+--------------------+----------------+----------------+-------------+--------------+\n",
      "| 8502471|  Kloten, Waldeggweg|47.4411280309022|8.57578482734645|         null|          null|\n",
      "| 8502508|Spreitenbach, Rai...|47.4163939893986|8.37617917118731|         null|          null|\n",
      "| 8503078|            Waldburg|47.3454699490061| 8.5930234976511|         null|          null|\n",
      "| 8503088|       Zürich HB SZU|47.3774340729037|8.53916949636064|         null|      8503088P|\n",
      "|8503101P|         Küsnacht ZH| 47.319156370147|8.58063572988137|            1|          null|\n",
      "+--------+--------------------+----------------+----------------+-------------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "@F.udf(returnType=FloatType())\n",
    "\n",
    "#Implement the Haversine formula. \n",
    "def distance_calculation(latitude_1, longitude_1, latitude_2, longitude_2):\n",
    "    #Use Haversine formula. \n",
    "    #The Haversine formula calculates the distance between two points on a sphere \n",
    "    #(such as the Earth) based on their latitude and longitude.\n",
    "    radius_of_Earth = 6371.0 #Earth radius, just refer to the actual data \n",
    "    \n",
    "    #First, Convert latitude and longitude from degrees to radians\n",
    "    latitude_1 = radians(float(latitude_1))\n",
    "    latitude_2 = radians(float(latitude_2))\n",
    "    longitude_1 = radians(float(longitude_1))\n",
    "    longitude_2 = radians(float(longitude_2))\n",
    "\n",
    "    ## Haversine formula implementation\n",
    "    delta_latitude = latitude_2 - latitude_1\n",
    "    delta_longitude = longitude_2 - longitude_1\n",
    "\n",
    "    a = cos(latitude_1)*cos(latitude_2)*sin(delta_longitude/2)**2+sin(delta_latitude/2)**2\n",
    "    c = 2*atan2(sqrt(a), sqrt(1-a))\n",
    "\n",
    "    distance = radius_of_Earth * c \n",
    "    return distance\n",
    "\n",
    "print(\"We have \" + str(stops_csv.distinct().count()) + \" stops before\")\n",
    "\n",
    "stops_in_15 = stops_csv.where(distance_calculation(F.lit(47.378177), F.lit(8.540192), F.col(\"stop_lat\"), F.col(\"stop_lon\")) <=15)\n",
    "\n",
    "print(\"There are \" + str(stops_in_15.distinct().count()) + \" stops that are in 15km radius of Zurich HB\")\n",
    "\n",
    "stops_in_15.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cc168-a81b-466f-a32a-df10874cb970",
   "metadata": {},
   "source": [
    "With the within-15km stops, we want to preprocess the walking time, for this there are two steps:\n",
    "- Filter out stations that are too far away for walking (>500m)\n",
    "- Calculate walking time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7045bb6f-d6f4-422c-80fc-6014e19c2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walking_df = stops_in_15.select(F.col(\"stop_id\").alias(\"stop_id_1\"), F.col(\"stop_name\").alias(\"stop_name_1\"), F.col(\"stop_lat\").alias(\"stop_lat_1\"), F.col(\"stop_lon\").alias(\"stop_lon_1\")) \\\n",
    "    .crossJoin(stops_in_15.select(F.col(\"stop_id\").alias(\"stop_id_2\"), F.col(\"stop_name\").alias(\"stop_name_2\"), F.col(\"stop_lat\").alias(\"stop_lat_2\"),F.col(\"stop_lon\").alias(\"stop_lon_2\"))) \\\n",
    "    .withColumn(\"distance\", distance_calculation(F.col(\"stop_lat_1\"), F.col(\"stop_lon_1\"), F.col(\"stop_lat_2\"), F.col(\"stop_lon_2\"))) \\\n",
    "    .select(F.col(\"stop_id_1\"), F.col(\"stop_name_1\"), F.col(\"stop_id_2\"), F.col(\"stop_name_2\"), F.col(\"distance\")) \\\n",
    "    .filter(\"distance<=0.5 and distance>0.0\")\n",
    "\n",
    "walking_df = walking_df.withColumn(\"used_time\", walking_df.distance*1200).select(\"stop_id_1\",\"stop_name_1\",\"stop_id_2\",\"stop_name_2\",\"used_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3f641-f0fe-4452-baad-4501ad75c399",
   "metadata": {},
   "source": [
    "sanity check:\n",
    "\n",
    "**Note: DONT TRY TO RUN `walking_df.count()`, IT KILLS THE SESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b72fd62-6757-485c-a53f-dbf553711140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------+--------------------+---------+\n",
      "|  stop_id_1|         stop_name_1|stop_id_2|         stop_name_2|used_time|\n",
      "+-----------+--------------------+---------+--------------------+---------+\n",
      "|    8573729|Bonstetten, Isenbach|  8573729|Bonstetten, Isenbach| 83.76533|\n",
      "|8503306:0:2|           Dietlikon|  8590541|Dietlikon, Dornen...|528.27905|\n",
      "|    8502471|  Kloten, Waldeggweg|  8580432|      Kloten, Bramen|441.21054|\n",
      "|    8506895|      Lufingen, Dorf|  8573228| Lufingen, Unterdorf|401.51526|\n",
      "|    8589111|Horgen, Gumelenst...| 8502208P|     Horgen Oberdorf|350.84717|\n",
      "+-----------+--------------------+---------+--------------------+---------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "walking_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab317fd-3131-47cd-b79f-f5305abfeb1b",
   "metadata": {},
   "source": [
    "According to the requirement of the task, we select only the weekdays.\n",
    "\n",
    "The weekdays filtering can be done in calendar and then we use service_id to join other dataframes to get the transportation methods in weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f94941f-8f53-4d63-9aa4-956d1a884fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weekdays_only = calendar.where(\"monday = 1 and tuesday = 1 and wednesday = 1 and thursday = 1 and friday = 1\").select('service_id').distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24047ff5-adb1-4503-946c-251ab99d5b04",
   "metadata": {},
   "source": [
    "We then implement all the joins using primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3607543-d928-4a5f-b50c-00a617e6a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o500.showString.\n",
      ": java.lang.OutOfMemoryError: Not enough memory to build and broadcast the table to all worker nodes. As a workaround, you can either disable broadcast by setting spark.sql.autoBroadcastJoinThreshold to -1 or increase the spark driver memory by setting spark.driver.memory to a higher value\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:122)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:76)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withExecutionId$1.apply(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionId(SQLExecution.scala:100)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:75)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:75)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 381, in show\n",
      "    print(self._jdf.showString(n, 20, vertical))\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o500.showString.\n",
      ": java.lang.OutOfMemoryError: Not enough memory to build and broadcast the table to all worker nodes. As a workaround, you can either disable broadcast by setting spark.sql.autoBroadcastJoinThreshold to -1 or increase the spark driver memory by setting spark.driver.memory to a higher value\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:122)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:76)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withExecutionId$1.apply(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionId(SQLExecution.scala:100)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:75)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:75)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weekday_trips = trips.join(weekdays_only, \"service_id\")\n",
    "weekday_trips = weekday_trips.join(routes.select(\"route_id\", \"route_desc\"), \"route_id\")\n",
    "\n",
    "weekday_trips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adaa8101-b422-472d-bc5b-43d2a5088b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o453.showString.\n",
      ": java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 381, in show\n",
      "    print(self._jdf.showString(n, 20, vertical))\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/cloudera/parcels/CDH-7.1.8-1.cdh7.1.8.p0.30990532/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o453.showString.\n",
      ": java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weekday_stop_times = stop_times.join(weekday_trips, \"trip_id\")\n",
    "\n",
    "weekday_stop_times = weekday_stop_times.drop(\"pickup_type\", \"drop_off_type\")\n",
    "\n",
    "weekday_stop_times.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c62142ff-dcea-44c9-8a4c-5ab570d73b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weekday_all_info = weekday_stop_times.join(stops_in_15, \"stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d92e43-39f9-49ed-b659-512d71b79d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
